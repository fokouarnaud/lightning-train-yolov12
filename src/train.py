#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module d'entraÃ®nement YOLOv12-Face optimisÃ© pour Lightning.ai
Utilise ultralytics YOLO avec des optimisations cloud
"""

import os
import logging
import time
from pathlib import Path
from typing import Dict, Any, Optional, Union

from ultralytics import YOLO
import torch
import yaml

from .lightning_utils import LightningLogger
from .data_manager import DataManager
from .model_manager import ModelManager

logger = logging.getLogger(__name__)

class YOLOv12FaceTrainer:
    """
    Trainer principal pour YOLOv12-Face sur Lightning.ai
    Simplifie l'interface d'ultralytics pour une utilisation optimisÃ©e
    """
    
    def __init__(
        self,
        config: Dict[str, Any],
        data_manager: DataManager,
        model_manager: ModelManager,
        logger: LightningLogger
    ):
        """
        Initialise le trainer
        
        Args:
            config: Configuration complÃ¨te du projet
            data_manager: Gestionnaire des donnÃ©es
            model_manager: Gestionnaire des modÃ¨les
            logger: Logger Lightning.ai
        """
        self.config = config
        self.data_manager = data_manager
        self.model_manager = model_manager
        self.lightning_logger = logger
        
        # Chemins de sortie
        self.output_dir = Path(config['output']['base_dir'])
        self.models_dir = Path(config['output']['models_dir'])
        self.logs_dir = Path(config['output']['logs_dir'])
        
        # CrÃ©er les dossiers de sortie
        self._create_output_dirs()
        
        # Initialiser le modÃ¨le YOLO
        self.model = None
        self._init_model()
        
        logger.info(f"âœ… YOLOv12FaceTrainer initialisÃ©")
        logger.info(f"ðŸ“ Sortie: {self.output_dir}")
        logger.info(f"ðŸŽ¯ ModÃ¨le: YOLOv12{config['model']['size']}")
    
    def _create_output_dirs(self) -> None:
        """CrÃ©e les dossiers de sortie nÃ©cessaires"""
        for dir_path in [self.output_dir, self.models_dir, self.logs_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def _init_model(self) -> None:
        """Initialise le modÃ¨le YOLO"""
        model_config = self.config['model']
        
        # Charger le modÃ¨le (prÃ©-entraÃ®nÃ© ou architecture vide)
        if model_config.get('pretrained'):
            model_path = model_config['pretrained']
            logger.info(f"ðŸ”„ Chargement du modÃ¨le prÃ©-entraÃ®nÃ©: {model_path}")
            self.model = YOLO(model_path)
        else:
            # CrÃ©er un modÃ¨le depuis l'architecture YAML
            yaml_path = model_config.get('yaml_path', f"yolov12{model_config['size']}.yaml")
            logger.info(f"ðŸ—ï¸ CrÃ©ation du modÃ¨le depuis: {yaml_path}")
            self.model = YOLO(yaml_path)
        
        # Adapter le nombre de classes si nÃ©cessaire
        if hasattr(self.model.model, 'yaml'):
            self.model.model.yaml['nc'] = model_config['num_classes']
    
    def train(self, resume_from: Optional[str] = None) -> Dict[str, Any]:
        """
        Lance l'entraÃ®nement du modÃ¨le
        
        Args:
            resume_from: Chemin vers un checkpoint pour reprendre l'entraÃ®nement
            
        Returns:
            Dictionnaire avec les rÃ©sultats d'entraÃ®nement
        """
        logger.info("ðŸš€ DÃ©marrage de l'entraÃ®nement YOLOv12-Face")
        
        # PrÃ©parer les donnÃ©es
        data_yaml_path = self.data_manager.prepare_dataset()
        
        # Configuration d'entraÃ®nement
        train_config = self.config['training']
        lightning_config = self.config['lightning']
        
        # ParamÃ¨tres d'entraÃ®nement optimisÃ©s pour Lightning.ai
        train_args = {
            # DonnÃ©es et modÃ¨le
            'data': str(data_yaml_path),
            'epochs': train_config['epochs'],
            'batch': train_config['batch_size'],
            'imgsz': train_config['img_size'],
            
            # Optimiseur et learning rate
            'optimizer': train_config['optimizer'],
            'lr0': train_config['lr0'],
            'lrf': train_config['lrf'],
            'momentum': train_config['momentum'],
            'weight_decay': train_config['weight_decay'],
            
            # RÃ©gularisation
            'box': train_config['box'],
            'cls': train_config['cls'],
            'obj': train_config['obj'],
            
            # Seuils
            'conf': train_config['conf_thres'],
            'iou': train_config['iou_thres'],
            
            # Augmentation
            'hsv_h': self.config['data']['augmentation']['hsv_h'],
            'hsv_s': self.config['data']['augmentation']['hsv_s'],
            'hsv_v': self.config['data']['augmentation']['hsv_v'],
            'degrees': self.config['data']['augmentation']['degrees'],
            'translate': self.config['data']['augmentation']['translate'],
            'scale': self.config['data']['augmentation']['scale'],
            'mosaic': self.config['data']['augmentation']['mosaic'],
            'mixup': self.config['data']['augmentation']['mixup'],
            
            # Sortie
            'project': str(self.output_dir),
            'name': self._generate_run_name(),
            'exist_ok': True,
            'save': True,
            'save_period': lightning_config.get('save_every_n_epochs', 10),
            
            # Optimisations Lightning.ai
            'cache': self.config['data'].get('cache', True),
            'device': self._get_device(),
            'workers': self.config['environment']['num_workers'],
            'amp': lightning_config['precision'] in ['16', '16-mixed'],
            
            # Monitoring
            'verbose': True,
            'plots': True,
        }
        
        # Reprendre l'entraÃ®nement si demandÃ©
        if resume_from:
            train_args['resume'] = resume_from
            logger.info(f"ðŸ”„ Reprise de l'entraÃ®nement depuis: {resume_from}")
        
        # Gestion des ressources pour Lightning.ai
        self._optimize_for_lightning()
        
        # Lancer l'entraÃ®nement
        start_time = time.time()
        try:
            logger.info(f"ðŸ‹ï¸ EntraÃ®nement en cours...")
            logger.info(f"ðŸ“Š ParamÃ¨tres: {train_config['epochs']} epochs, batch={train_config['batch_size']}, img={train_config['img_size']}")
            
            results = self.model.train(**train_args)
            
            training_time = time.time() - start_time
            logger.info(f"âœ… EntraÃ®nement terminÃ© en {training_time:.2f}s")
            
            # Sauvegarder les rÃ©sultats
            self._save_training_results(results, training_time)
            
            return {
                'success': True,
                'results': results,
                'training_time': training_time,
                'best_model_path': str(self.model.trainer.best),
                'last_model_path': str(self.model.trainer.last)
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur pendant l'entraÃ®nement: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'training_time': time.time() - start_time
            }
    
    def evaluate(self, model_path: Optional[str] = None) -> Dict[str, Any]:
        """
        Ã‰value le modÃ¨le sur le dataset de validation
        
        Args:
            model_path: Chemin vers le modÃ¨le Ã  Ã©valuer (utilise le meilleur si None)
            
        Returns:
            Dictionnaire avec les rÃ©sultats d'Ã©valuation
        """
        logger.info("ðŸ“Š Ã‰valuation du modÃ¨le")
        
        # Utiliser le meilleur modÃ¨le par dÃ©faut
        if model_path is None and hasattr(self.model, 'trainer'):
            model_path = self.model.trainer.best
        
        # Charger le modÃ¨le Ã  Ã©valuer
        if model_path and os.path.exists(model_path):
            eval_model = YOLO(model_path)
            logger.info(f"ðŸ“ˆ Ã‰valuation du modÃ¨le: {model_path}")
        else:
            eval_model = self.model
            logger.info("ðŸ“ˆ Ã‰valuation du modÃ¨le actuel")
        
        # Configuration d'Ã©valuation
        eval_config = self.config['evaluation']
        
        try:
            # Lancer l'Ã©valuation
            results = eval_model.val(
                data=str(self.data_manager.data_yaml_path),
                imgsz=self.config['training']['img_size'],
                conf=eval_config['conf_thres'],
                iou=eval_config['iou_thres'],
                save_txt=eval_config.get('save_txt', True),
                save_conf=eval_config.get('save_conf', True),
                save_json=eval_config.get('save_json', True),
                plots=eval_config.get('save_plots', True),
                project=str(self.output_dir),
                name='evaluation',
                exist_ok=True
            )
            
            logger.info("âœ… Ã‰valuation terminÃ©e")
            return {
                'success': True,
                'results': results,
                'metrics': results.results_dict if hasattr(results, 'results_dict') else {}
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur pendant l'Ã©valuation: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def export(self, model_path: Optional[str] = None, format: str = 'onnx') -> Dict[str, Any]:
        """
        Exporte le modÃ¨le vers diffÃ©rents formats
        
        Args:
            model_path: Chemin vers le modÃ¨le Ã  exporter
            format: Format d'export (onnx, torchscript, coreml, etc.)
            
        Returns:
            Dictionnaire avec les informations d'export
        """
        logger.info(f"ðŸ“¦ Export du modÃ¨le en format {format}")
        
        # Utiliser le meilleur modÃ¨le par dÃ©faut
        if model_path is None and hasattr(self.model, 'trainer'):
            model_path = self.model.trainer.best
        
        # Charger le modÃ¨le Ã  exporter
        if model_path and os.path.exists(model_path):
            export_model = YOLO(model_path)
            logger.info(f"ðŸ“¤ Export du modÃ¨le: {model_path}")
        else:
            export_model = self.model
            logger.info("ðŸ“¤ Export du modÃ¨le actuel")
        
        # Configuration d'export
        export_config = self.config['export']
        
        try:
            # ParamÃ¨tres d'export selon le format
            export_args = {
                'format': format,
                'imgsz': self.config['training']['img_size'],
                'device': self._get_device(),
                'half': self.config['lightning']['precision'] in ['16', '16-mixed'],
                'simplify': True,  # Simplifier le modÃ¨le ONNX
                'workspace': 4,    # Workspace pour TensorRT
                'verbose': True
            }
            
            # Options spÃ©cifiques ONNX
            if format == 'onnx':
                onnx_config = export_config.get('onnx', {})
                export_args.update({
                    'opset': onnx_config.get('opset', 12),
                    'simplify': onnx_config.get('simplify', True),
                    'dynamic': onnx_config.get('dynamic', False)
                })
            
            # Lancer l'export
            exported_model = export_model.export(**export_args)
            
            # DÃ©placer vers le dossier d'export
            export_dir = Path(self.config['output']['exports_dir'])
            export_dir.mkdir(parents=True, exist_ok=True)
            
            logger.info(f"âœ… Export terminÃ©: {exported_model}")
            
            return {
                'success': True,
                'exported_model': str(exported_model),
                'format': format,
                'size_mb': os.path.getsize(exported_model) / (1024 * 1024) if os.path.exists(exported_model) else 0
            }
            
        except Exception as e:
            logger.error(f"âŒ Erreur pendant l'export: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'format': format
            }
    
    def _get_device(self) -> str:
        """DÃ©termine le device optimal pour Lightning.ai"""
        if torch.cuda.is_available():
            return 'cuda'
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return 'mps'
        else:
            return 'cpu'
    
    def _generate_run_name(self) -> str:
        """GÃ©nÃ¨re un nom unique pour ce run"""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        model_size = self.config['model']['size']
        return f"yolov12{model_size}_{timestamp}"
    
    def _optimize_for_lightning(self) -> None:
        """Optimisations spÃ©cifiques Ã  Lightning.ai"""
        # Optimisations mÃ©moire
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # Configuration des workers
        os.environ['PYTHONPATH'] = self.config['environment']['pythonpath']
        
        # Graine pour la reproductibilitÃ©
        if 'seed' in self.config['environment']:
            torch.manual_seed(self.config['environment']['seed'])
        
        logger.info("âš¡ Optimisations Lightning.ai appliquÃ©es")
    
    def _save_training_results(self, results: Any, training_time: float) -> None:
        """Sauvegarde les rÃ©sultats d'entraÃ®nement"""
        results_dict = {
            'training_time': training_time,
            'config': self.config,
            'model_info': {
                'size': self.config['model']['size'],
                'num_classes': self.config['model']['num_classes'],
                'img_size': self.config['training']['img_size']
            }
        }
        
        # Sauvegarder en YAML
        results_file = self.output_dir / 'training_results.yaml'
        with open(results_file, 'w') as f:
            yaml.dump(results_dict, f, default_flow_style=False)
        
        logger.info(f"ðŸ’¾ RÃ©sultats sauvegardÃ©s: {results_file}")
